{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\D\\Internship\\Adamata\\trash-classification\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datasets\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.datasets import load_files\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code only can run after import the wandb\n",
    "from wandb.integration.keras import WandbModelCheckpoint, WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\"garythung/trashnet\", split=datasets.ReadInstruction(\"train\", from_=2527, to=5054, unit=\"abs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load path on .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check .env availability\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except ImportError:\n",
    "    print(\"python-dotenv is not installed. Please install it by running:\")\n",
    "    print(\"pip install python-dotenv\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def check_env_file():\n",
    "    \"\"\"\n",
    "    Attempt to load environment variables from a .env file.\n",
    "    Returns True if .env was found and successfully loaded,\n",
    "    otherwise returns False.\n",
    "    \"\"\"\n",
    "    # load_dotenv() returns True if at least one environment variable\n",
    "    # was set, or if the .env file was found. Otherwise, returns False.\n",
    "    return load_dotenv()\n",
    "\n",
    "if check_env_file():\n",
    "    print(\".env file found and environment variables are loaded.\")\n",
    "else:\n",
    "    print(\"No .env file found or environment variables were not set.\")\n",
    "\n",
    "# Check if specific variables are set\n",
    "data_url = os.getenv(\"DATA_URL\")\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "dataset_dict = os.getenv(\"DATASET_DICT\")\n",
    "artifact_dir = os.getenv(\"ARTIFACT_DIR\")\n",
    "\n",
    "if not data_url:\n",
    "    print(\"WARNING: DATA_URL not set.\")\n",
    "    sys.exit(1)    \n",
    "if not wandb_api_key:\n",
    "    print(\"WARNING: WANDB_API not set.\")\n",
    "    sys.exit(1)\n",
    "if not dataset_dict:\n",
    "    print(\"WARNING: DATASET_DICT not set.\")\n",
    "    sys.exit(1)\n",
    "if not artifact_dir:\n",
    "    print(\"WARNING: ARTIFACT_DIR not set.\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33magungadipurwa\u001b[0m (\u001b[33magungadipurwa_\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\D\\Internship\\Adamata\\trash-classification\\wandb\\run-20241222_213430-mmu9pem7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agungadipurwa_/trashnet-classification/runs/mmu9pem7' target=\"_blank\">bright-spaceship-12</a></strong> to <a href='https://wandb.ai/agungadipurwa_/trashnet-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agungadipurwa_/trashnet-classification' target=\"_blank\">https://wandb.ai/agungadipurwa_/trashnet-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agungadipurwa_/trashnet-classification/runs/mmu9pem7' target=\"_blank\">https://wandb.ai/agungadipurwa_/trashnet-classification/runs/mmu9pem7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2528 of 2528 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "#create metadata\n",
    "job_type = \"train_model\"\n",
    "config = {\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"metrics\": [\"acc\"],\n",
    "    \"epochs\": 100,\n",
    "    \"validation_split\": 0.1,\n",
    "}\n",
    "\n",
    "#initialization wandb for create the run session\n",
    "run = wandb.init(\n",
    "    project=\"trashnet-classification\",\n",
    "    job_type=job_type,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "#access the latest dataset version with artifact then dowload\n",
    "version = \"latest\"\n",
    "name = \"{}:{}\".format(\"{}_dataset\".format(\"trashnet\"), version)\n",
    "artifact = run.use_artifact(artifact_or_name=name)\n",
    "\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_data=os.path.join(os.getcwd(),os.getenv(\"ARTIFACT_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the config of metadata model versioning \n",
    "input_shape = (300, 300, 3)\n",
    "loss = \"categorical_crossentropy\"\n",
    "optimizer = run.config[\"optimizer\"]\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = run.config[\"epochs\"]\n",
    "validation_split = run.config[\"validation_split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2527 files belonging to 6 classes.\n",
      "Using 2275 files for training.\n",
      "Found 2527 files belonging to 6 classes.\n",
      "Using 252 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Generate tensorflow/keras dataset format from downloades artifacts dataset version \n",
    "\n",
    "#Generate train dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  artifact_data,\n",
    "  validation_split=validation_split, #split by 90:10\n",
    "  subset=\"training\",\n",
    "  seed=123, #make shuffle dataset from next generate\n",
    "  image_size=(300, 300),\n",
    "  batch_size=32,\n",
    "  label_mode=\"categorical\") #make sure label_mode on categorical so the target shape will (None, num_classes)\n",
    "\n",
    "#Generate validation/test dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  artifact_data,\n",
    "  validation_split=validation_split,#split by 90:10\n",
    "  subset=\"validation\",\n",
    "  seed=123, #make shuffle dataset from next generate\n",
    "  image_size=(300, 300),\n",
    "  batch_size=32,\n",
    "  label_mode=\"categorical\")#make sure label_mode on categorical so the target shape will (None, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(train_ds.class_names) #count the number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model(input_shape,classes):\n",
    "    #Generate manual augmentation layer without generator\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomRotation(0.4),\n",
    "        layers.RandomTranslation(0.2, 0.2),\n",
    "        # layers.RandomZoom(0.1),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.Rescaling(1./255)\n",
    "    ])\n",
    "    X_Input = layers.Input(input_shape)\n",
    "    X = data_augmentation(X_Input) #augmented data before convulation\n",
    "\n",
    "    #Convolution blocks\n",
    "    X = layers.Conv2D(32,(3,3), padding='same',activation='relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size=2)(X)\n",
    "\n",
    "    X = layers.Conv2D(64,(3,3), padding='same',activation='relu')(X)\n",
    "    X =layers.MaxPooling2D(pool_size=2)(X)\n",
    "\n",
    "    X = layers.Conv2D(32,(3,3), padding='same',activation='relu')(X)\n",
    "    X = layers.MaxPooling2D(pool_size=2)(X)\n",
    "\n",
    "    #Classification layers\n",
    "    X = layers.Flatten()(X)\n",
    "\n",
    "    X = layers.Dense(64,activation='relu')(X)\n",
    "\n",
    "    X = layers.Dropout(0.2)(X)\n",
    "    X = layers.Dense(32,activation='relu')(X)\n",
    "\n",
    "    X = layers.Dropout(0.2)(X)\n",
    "    X = layers.Dense(classes,activation='softmax')(X)\n",
    "\n",
    "    model = Model(inputs=X_Input,outputs=X, name=\"CNN\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the architecure model\n",
    "model = CNN_Model(input_shape, n_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model with the optimizer, loss, and metric config\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43808</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,803,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43808\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m2,803,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,843,910</span> (10.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,843,910\u001b[0m (10.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,843,910</span> (10.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,843,910\u001b[0m (10.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a custom callback Class for stoping traing base of the threshold\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs=None):\n",
    "        #will stop the traning if validation accuracy and train accuracy higher than 90% or 99%\n",
    "        if logs.get('val_accuracy') >= 0.90 or logs.get('accuracy') >= 0.99:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of callback method\n",
    "callbacks_list = [\n",
    "    #model checkpoint for local tracking\n",
    "    ModelCheckpoint(\n",
    "        filepath=\"ckpt/cnn_v2.weights.h5\",\n",
    "        monitor=metrics[0],\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        save_freq=\"epoch\"),\n",
    "\n",
    "    #model log for every epoch\n",
    "    WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "\n",
    "    #model checkpoint for tracking on Wandb\n",
    "    WandbModelCheckpoint(\n",
    "        filepath=\"ckpt/cnn_v2.weights.h5\",\n",
    "        monitor=metrics[0],\n",
    "        mode=\"max\",\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        save_freq=\"epoch\"),\n",
    "\n",
    "    #model stopping when reach the threshold\n",
    "    CustomCallback()\n",
    "\n",
    "    ##additional callback for experiment\n",
    "    # ReduceLROnPlateau(\n",
    "    #     monitor=metrics[0],       # Monitor Validation Loss Metric\n",
    "    #     factor=0.5,               # Reduce learning rate around 50%\n",
    "    #     patience=2,               # Reduce Learning Rate if didn't improvement while 5 epoch\n",
    "    #     verbose=1,                # Showing Log\n",
    "    #     min_lr=1e-6),               # Learning rate minimum\n",
    "\n",
    "    # EarlyStopping(\n",
    "    #     monitor=\"val_accuracy\",\n",
    "    #     mode=\"max\",\n",
    "    #     verbose=1,\n",
    "    #     baseline=0.95,\n",
    "    #     restore_best_weights=True)\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the Exploratory Data Analysis (EDA), that some problem with imbalanced data. The code below will try to deal with imbalanced data with balancing the class weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deals with Imbalanced Data\n",
    "\n",
    "#Store all label\n",
    "y_train = np.array(ds[\"label\"])\n",
    "\n",
    "#Compute the class weigth data dan store in array\n",
    "#Idea of balanced weight is greated the weight of minority class\n",
    "#Balanced formula: number of label(y_train)/number of the class\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957ms/step - accuracy: 0.2368 - loss: 1.7258\n",
      "Epoch 1: accuracy improved from -inf to 0.22769, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 998ms/step - accuracy: 0.2367 - loss: 1.7258 - val_accuracy: 0.2024 - val_loss: 1.6568\n",
      "Epoch 2/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903ms/step - accuracy: 0.2753 - loss: 1.6651\n",
      "Epoch 2: accuracy improved from 0.22769 to 0.31341, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 933ms/step - accuracy: 0.2759 - loss: 1.6644 - val_accuracy: 0.3254 - val_loss: 2.1299\n",
      "Epoch 3/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2852 - loss: 1.6856\n",
      "Epoch 3: accuracy improved from 0.31341 to 0.32967, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.2858 - loss: 1.6845 - val_accuracy: 0.4286 - val_loss: 1.4552\n",
      "Epoch 4/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4138 - loss: 1.4771\n",
      "Epoch 4: accuracy improved from 0.32967 to 0.40659, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.4137 - loss: 1.4771 - val_accuracy: 0.4444 - val_loss: 1.4436\n",
      "Epoch 5/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4380 - loss: 1.4176\n",
      "Epoch 5: accuracy improved from 0.40659 to 0.43516, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.4380 - loss: 1.4174 - val_accuracy: 0.4643 - val_loss: 1.3393\n",
      "Epoch 6/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4177 - loss: 1.4641\n",
      "Epoch 6: accuracy did not improve from 0.43516\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.4180 - loss: 1.4635 - val_accuracy: 0.4722 - val_loss: 1.3390\n",
      "Epoch 7/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.4459 - loss: 1.3559\n",
      "Epoch 7: accuracy improved from 0.43516 to 0.43824, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 822ms/step - accuracy: 0.4458 - loss: 1.3559 - val_accuracy: 0.4881 - val_loss: 1.2375\n",
      "Epoch 8/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.4798 - loss: 1.3143\n",
      "Epoch 8: accuracy improved from 0.43824 to 0.46110, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 497ms/step - accuracy: 0.4793 - loss: 1.3150 - val_accuracy: 0.4762 - val_loss: 1.2711\n",
      "Epoch 9/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.4574 - loss: 1.3347\n",
      "Epoch 9: accuracy improved from 0.46110 to 0.46462, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 415ms/step - accuracy: 0.4576 - loss: 1.3342 - val_accuracy: 0.5040 - val_loss: 1.2373\n",
      "Epoch 10/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.4763 - loss: 1.3087\n",
      "Epoch 10: accuracy improved from 0.46462 to 0.47736, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 415ms/step - accuracy: 0.4763 - loss: 1.3083 - val_accuracy: 0.4881 - val_loss: 1.2409\n",
      "Epoch 11/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.4649 - loss: 1.3306\n",
      "Epoch 11: accuracy did not improve from 0.47736\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 408ms/step - accuracy: 0.4652 - loss: 1.3297 - val_accuracy: 0.4921 - val_loss: 1.2034\n",
      "Epoch 12/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4733 - loss: 1.3081\n",
      "Epoch 12: accuracy improved from 0.47736 to 0.49099, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.4738 - loss: 1.3072 - val_accuracy: 0.5317 - val_loss: 1.1340\n",
      "Epoch 13/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.5167 - loss: 1.2349\n",
      "Epoch 13: accuracy improved from 0.49099 to 0.50857, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 416ms/step - accuracy: 0.5165 - loss: 1.2351 - val_accuracy: 0.4841 - val_loss: 1.2346\n",
      "Epoch 14/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.5007 - loss: 1.2588\n",
      "Epoch 14: accuracy improved from 0.50857 to 0.51516, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 409ms/step - accuracy: 0.5011 - loss: 1.2577 - val_accuracy: 0.5595 - val_loss: 1.1852\n",
      "Epoch 15/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.5252 - loss: 1.2301\n",
      "Epoch 15: accuracy improved from 0.51516 to 0.53099, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 428ms/step - accuracy: 0.5253 - loss: 1.2294 - val_accuracy: 0.5595 - val_loss: 1.0924\n",
      "Epoch 16/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.5249 - loss: 1.1928\n",
      "Epoch 16: accuracy did not improve from 0.53099\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 427ms/step - accuracy: 0.5250 - loss: 1.1924 - val_accuracy: 0.5873 - val_loss: 1.0523\n",
      "Epoch 17/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.5374 - loss: 1.1793\n",
      "Epoch 17: accuracy improved from 0.53099 to 0.53582, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 429ms/step - accuracy: 0.5374 - loss: 1.1794 - val_accuracy: 0.5833 - val_loss: 1.0857\n",
      "Epoch 18/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.4852 - loss: 1.2791\n",
      "Epoch 18: accuracy did not improve from 0.53582\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 412ms/step - accuracy: 0.4860 - loss: 1.2777 - val_accuracy: 0.5714 - val_loss: 1.1680\n",
      "Epoch 19/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.5397 - loss: 1.2183\n",
      "Epoch 19: accuracy improved from 0.53582 to 0.54110, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 421ms/step - accuracy: 0.5398 - loss: 1.2179 - val_accuracy: 0.5675 - val_loss: 1.0806\n",
      "Epoch 20/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.5526 - loss: 1.1478\n",
      "Epoch 20: accuracy improved from 0.54110 to 0.56132, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 419ms/step - accuracy: 0.5528 - loss: 1.1474 - val_accuracy: 0.6151 - val_loss: 0.9806\n",
      "Epoch 21/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.5582 - loss: 1.1497\n",
      "Epoch 21: accuracy did not improve from 0.56132\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 437ms/step - accuracy: 0.5581 - loss: 1.1496 - val_accuracy: 0.6190 - val_loss: 0.9949\n",
      "Epoch 22/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.5665 - loss: 1.1369\n",
      "Epoch 22: accuracy improved from 0.56132 to 0.58637, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 421ms/step - accuracy: 0.5670 - loss: 1.1356 - val_accuracy: 0.6548 - val_loss: 0.9604\n",
      "Epoch 23/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.5666 - loss: 1.1096\n",
      "Epoch 23: accuracy did not improve from 0.58637\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 423ms/step - accuracy: 0.5665 - loss: 1.1099 - val_accuracy: 0.6071 - val_loss: 1.0774\n",
      "Epoch 24/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.5753 - loss: 1.1365\n",
      "Epoch 24: accuracy did not improve from 0.58637\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 568ms/step - accuracy: 0.5753 - loss: 1.1361 - val_accuracy: 0.6548 - val_loss: 0.9612\n",
      "Epoch 25/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.5952 - loss: 1.0709\n",
      "Epoch 25: accuracy improved from 0.58637 to 0.59912, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 817ms/step - accuracy: 0.5952 - loss: 1.0708 - val_accuracy: 0.6190 - val_loss: 0.9786\n",
      "Epoch 26/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5783 - loss: 1.1069\n",
      "Epoch 26: accuracy did not improve from 0.59912\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.5786 - loss: 1.1060 - val_accuracy: 0.6508 - val_loss: 0.9268\n",
      "Epoch 27/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.6012 - loss: 1.0424\n",
      "Epoch 27: accuracy improved from 0.59912 to 0.60747, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 676ms/step - accuracy: 0.6014 - loss: 1.0424 - val_accuracy: 0.6508 - val_loss: 0.9271\n",
      "Epoch 28/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.5962 - loss: 1.0842\n",
      "Epoch 28: accuracy improved from 0.60747 to 0.61011, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 627ms/step - accuracy: 0.5966 - loss: 1.0836 - val_accuracy: 0.6310 - val_loss: 0.9383\n",
      "Epoch 29/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.5927 - loss: 1.0928\n",
      "Epoch 29: accuracy did not improve from 0.61011\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 394ms/step - accuracy: 0.5928 - loss: 1.0920 - val_accuracy: 0.6786 - val_loss: 0.9121\n",
      "Epoch 30/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.6070 - loss: 1.0451\n",
      "Epoch 30: accuracy did not improve from 0.61011\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 414ms/step - accuracy: 0.6070 - loss: 1.0449 - val_accuracy: 0.6548 - val_loss: 0.9008\n",
      "Epoch 31/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6008 - loss: 1.0641\n",
      "Epoch 31: accuracy improved from 0.61011 to 0.61626, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.6012 - loss: 1.0638 - val_accuracy: 0.6032 - val_loss: 1.0386\n",
      "Epoch 32/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.5890 - loss: 1.0827\n",
      "Epoch 32: accuracy did not improve from 0.61626\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 494ms/step - accuracy: 0.5896 - loss: 1.0814 - val_accuracy: 0.6190 - val_loss: 1.0084\n",
      "Epoch 33/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.6052 - loss: 1.0537\n",
      "Epoch 33: accuracy improved from 0.61626 to 0.62110, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 430ms/step - accuracy: 0.6057 - loss: 1.0522 - val_accuracy: 0.6706 - val_loss: 0.8934\n",
      "Epoch 34/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.6260 - loss: 1.0318\n",
      "Epoch 34: accuracy improved from 0.62110 to 0.63692, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 431ms/step - accuracy: 0.6263 - loss: 1.0308 - val_accuracy: 0.6825 - val_loss: 0.8479\n",
      "Epoch 35/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.6174 - loss: 1.0326\n",
      "Epoch 35: accuracy did not improve from 0.63692\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 420ms/step - accuracy: 0.6173 - loss: 1.0327 - val_accuracy: 0.6706 - val_loss: 0.8750\n",
      "Epoch 36/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.6188 - loss: 1.0151\n",
      "Epoch 36: accuracy improved from 0.63692 to 0.63868, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 422ms/step - accuracy: 0.6193 - loss: 1.0141 - val_accuracy: 0.6984 - val_loss: 0.8419\n",
      "Epoch 37/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.6369 - loss: 0.9678\n",
      "Epoch 37: accuracy improved from 0.63868 to 0.64308, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 428ms/step - accuracy: 0.6371 - loss: 0.9676 - val_accuracy: 0.5873 - val_loss: 1.2115\n",
      "Epoch 38/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.6236 - loss: 1.0455\n",
      "Epoch 38: accuracy did not improve from 0.64308\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 424ms/step - accuracy: 0.6240 - loss: 1.0439 - val_accuracy: 0.6825 - val_loss: 0.9227\n",
      "Epoch 39/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.6270 - loss: 1.0095\n",
      "Epoch 39: accuracy did not improve from 0.64308\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 411ms/step - accuracy: 0.6273 - loss: 1.0086 - val_accuracy: 0.7103 - val_loss: 0.8857\n",
      "Epoch 40/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6259 - loss: 0.9893\n",
      "Epoch 40: accuracy did not improve from 0.64308\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 413ms/step - accuracy: 0.6262 - loss: 0.9887 - val_accuracy: 0.6984 - val_loss: 0.8410\n",
      "Epoch 41/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.6251 - loss: 0.9970\n",
      "Epoch 41: accuracy improved from 0.64308 to 0.65714, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 420ms/step - accuracy: 0.6260 - loss: 0.9954 - val_accuracy: 0.6905 - val_loss: 0.8174\n",
      "Epoch 42/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.6230 - loss: 1.0327\n",
      "Epoch 42: accuracy did not improve from 0.65714\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 433ms/step - accuracy: 0.6235 - loss: 1.0313 - val_accuracy: 0.6746 - val_loss: 0.9011\n",
      "Epoch 43/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.6302 - loss: 0.9693\n",
      "Epoch 43: accuracy did not improve from 0.65714\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 418ms/step - accuracy: 0.6308 - loss: 0.9681 - val_accuracy: 0.6825 - val_loss: 0.8656\n",
      "Epoch 44/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.6448 - loss: 0.9649\n",
      "Epoch 44: accuracy improved from 0.65714 to 0.66813, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 422ms/step - accuracy: 0.6454 - loss: 0.9638 - val_accuracy: 0.7024 - val_loss: 0.8317\n",
      "Epoch 45/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.6351 - loss: 0.9823\n",
      "Epoch 45: accuracy did not improve from 0.66813\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 427ms/step - accuracy: 0.6356 - loss: 0.9814 - val_accuracy: 0.6984 - val_loss: 0.8044\n",
      "Epoch 46/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.6504 - loss: 0.9361\n",
      "Epoch 46: accuracy did not improve from 0.66813\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 428ms/step - accuracy: 0.6505 - loss: 0.9359 - val_accuracy: 0.6786 - val_loss: 0.8416\n",
      "Epoch 47/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.6297 - loss: 0.9851\n",
      "Epoch 47: accuracy did not improve from 0.66813\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 400ms/step - accuracy: 0.6304 - loss: 0.9838 - val_accuracy: 0.6865 - val_loss: 0.8533\n",
      "Epoch 48/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.5916 - loss: 1.1014\n",
      "Epoch 48: accuracy did not improve from 0.66813\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 534ms/step - accuracy: 0.5928 - loss: 1.0991 - val_accuracy: 0.6905 - val_loss: 0.8471\n",
      "Epoch 49/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.6560 - loss: 0.9448\n",
      "Epoch 49: accuracy improved from 0.66813 to 0.67297, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 391ms/step - accuracy: 0.6564 - loss: 0.9442 - val_accuracy: 0.7183 - val_loss: 0.7883\n",
      "Epoch 50/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6500 - loss: 0.9355\n",
      "Epoch 50: accuracy did not improve from 0.67297\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 414ms/step - accuracy: 0.6504 - loss: 0.9347 - val_accuracy: 0.6905 - val_loss: 0.7848\n",
      "Epoch 51/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.6617 - loss: 0.9234\n",
      "Epoch 51: accuracy did not improve from 0.67297\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 415ms/step - accuracy: 0.6620 - loss: 0.9223 - val_accuracy: 0.7262 - val_loss: 0.7553\n",
      "Epoch 52/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.6687 - loss: 0.8835\n",
      "Epoch 52: accuracy improved from 0.67297 to 0.67648, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 403ms/step - accuracy: 0.6689 - loss: 0.8832 - val_accuracy: 0.6905 - val_loss: 0.8221\n",
      "Epoch 53/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.6860 - loss: 0.9031\n",
      "Epoch 53: accuracy improved from 0.67648 to 0.69231, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 398ms/step - accuracy: 0.6862 - loss: 0.9023 - val_accuracy: 0.7024 - val_loss: 0.7817\n",
      "Epoch 54/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.6529 - loss: 0.9080\n",
      "Epoch 54: accuracy did not improve from 0.69231\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 516ms/step - accuracy: 0.6535 - loss: 0.9072 - val_accuracy: 0.7262 - val_loss: 0.8103\n",
      "Epoch 55/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.6404 - loss: 0.9602\n",
      "Epoch 55: accuracy did not improve from 0.69231\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 558ms/step - accuracy: 0.6412 - loss: 0.9581 - val_accuracy: 0.7222 - val_loss: 0.7813\n",
      "Epoch 56/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6707 - loss: 0.9117\n",
      "Epoch 56: accuracy did not improve from 0.69231\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.6709 - loss: 0.9113 - val_accuracy: 0.7460 - val_loss: 0.7549\n",
      "Epoch 57/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6553 - loss: 0.9261\n",
      "Epoch 57: accuracy did not improve from 0.69231\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.6560 - loss: 0.9252 - val_accuracy: 0.7183 - val_loss: 0.7789\n",
      "Epoch 58/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.6746 - loss: 0.9165\n",
      "Epoch 58: accuracy did not improve from 0.69231\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 416ms/step - accuracy: 0.6749 - loss: 0.9156 - val_accuracy: 0.7302 - val_loss: 0.7657\n",
      "Epoch 59/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.6830 - loss: 0.8570\n",
      "Epoch 59: accuracy improved from 0.69231 to 0.69363, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 411ms/step - accuracy: 0.6833 - loss: 0.8563 - val_accuracy: 0.7421 - val_loss: 0.7602\n",
      "Epoch 60/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.6633 - loss: 0.9143\n",
      "Epoch 60: accuracy did not improve from 0.69363\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 405ms/step - accuracy: 0.6640 - loss: 0.9125 - val_accuracy: 0.7421 - val_loss: 0.7427\n",
      "Epoch 61/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 681ms/step - accuracy: 0.6977 - loss: 0.8538\n",
      "Epoch 61: accuracy improved from 0.69363 to 0.70242, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 689ms/step - accuracy: 0.6979 - loss: 0.8532 - val_accuracy: 0.7222 - val_loss: 0.7242\n",
      "Epoch 62/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.7021 - loss: 0.8282\n",
      "Epoch 62: accuracy did not improve from 0.70242\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 405ms/step - accuracy: 0.7021 - loss: 0.8283 - val_accuracy: 0.7063 - val_loss: 0.7913\n",
      "Epoch 63/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.6693 - loss: 0.8757\n",
      "Epoch 63: accuracy did not improve from 0.70242\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 409ms/step - accuracy: 0.6700 - loss: 0.8743 - val_accuracy: 0.7063 - val_loss: 0.7830\n",
      "Epoch 64/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.6647 - loss: 0.8886\n",
      "Epoch 64: accuracy did not improve from 0.70242\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 422ms/step - accuracy: 0.6653 - loss: 0.8874 - val_accuracy: 0.7183 - val_loss: 0.8025\n",
      "Epoch 65/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6679 - loss: 0.8898\n",
      "Epoch 65: accuracy did not improve from 0.70242\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 413ms/step - accuracy: 0.6682 - loss: 0.8893 - val_accuracy: 0.6944 - val_loss: 0.7973\n",
      "Epoch 66/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.6639 - loss: 0.8623\n",
      "Epoch 66: accuracy did not improve from 0.70242\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 390ms/step - accuracy: 0.6646 - loss: 0.8612 - val_accuracy: 0.7341 - val_loss: 0.7600\n",
      "Epoch 67/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7018 - loss: 0.8782\n",
      "Epoch 67: accuracy improved from 0.70242 to 0.71253, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 394ms/step - accuracy: 0.7021 - loss: 0.8770 - val_accuracy: 0.7540 - val_loss: 0.7396\n",
      "Epoch 68/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.6978 - loss: 0.8394\n",
      "Epoch 68: accuracy did not improve from 0.71253\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 401ms/step - accuracy: 0.6980 - loss: 0.8387 - val_accuracy: 0.7302 - val_loss: 0.7265\n",
      "Epoch 69/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.7174 - loss: 0.7848\n",
      "Epoch 69: accuracy did not improve from 0.71253\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 419ms/step - accuracy: 0.7171 - loss: 0.7850 - val_accuracy: 0.7381 - val_loss: 0.7105\n",
      "Epoch 70/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.6835 - loss: 0.8688\n",
      "Epoch 70: accuracy did not improve from 0.71253\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 452ms/step - accuracy: 0.6842 - loss: 0.8676 - val_accuracy: 0.7381 - val_loss: 0.7521\n",
      "Epoch 71/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.6752 - loss: 0.8360\n",
      "Epoch 71: accuracy did not improve from 0.71253\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 436ms/step - accuracy: 0.6758 - loss: 0.8355 - val_accuracy: 0.7381 - val_loss: 0.7343\n",
      "Epoch 72/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.7075 - loss: 0.8118\n",
      "Epoch 72: accuracy did not improve from 0.71253\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 406ms/step - accuracy: 0.7076 - loss: 0.8114 - val_accuracy: 0.7341 - val_loss: 0.7454\n",
      "Epoch 73/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7052 - loss: 0.8518\n",
      "Epoch 73: accuracy improved from 0.71253 to 0.71648, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 403ms/step - accuracy: 0.7055 - loss: 0.8507 - val_accuracy: 0.7302 - val_loss: 0.7390\n",
      "Epoch 74/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.7148 - loss: 0.8100\n",
      "Epoch 74: accuracy did not improve from 0.71648\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 594ms/step - accuracy: 0.7148 - loss: 0.8097 - val_accuracy: 0.7421 - val_loss: 0.7182\n",
      "Epoch 75/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - accuracy: 0.7056 - loss: 0.8041\n",
      "Epoch 75: accuracy did not improve from 0.71648\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 490ms/step - accuracy: 0.7059 - loss: 0.8037 - val_accuracy: 0.7183 - val_loss: 0.7488\n",
      "Epoch 76/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7146 - loss: 0.7827\n",
      "Epoch 76: accuracy improved from 0.71648 to 0.72571, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 415ms/step - accuracy: 0.7149 - loss: 0.7823 - val_accuracy: 0.7183 - val_loss: 0.7326\n",
      "Epoch 77/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.6997 - loss: 0.8198\n",
      "Epoch 77: accuracy did not improve from 0.72571\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 426ms/step - accuracy: 0.6999 - loss: 0.8195 - val_accuracy: 0.7302 - val_loss: 0.7024\n",
      "Epoch 78/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.7047 - loss: 0.8396\n",
      "Epoch 78: accuracy did not improve from 0.72571\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 414ms/step - accuracy: 0.7053 - loss: 0.8382 - val_accuracy: 0.7222 - val_loss: 0.7040\n",
      "Epoch 79/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.6868 - loss: 0.8130\n",
      "Epoch 79: accuracy did not improve from 0.72571\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 431ms/step - accuracy: 0.6877 - loss: 0.8115 - val_accuracy: 0.7143 - val_loss: 0.6975\n",
      "Epoch 80/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.7046 - loss: 0.8182\n",
      "Epoch 80: accuracy did not improve from 0.72571\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 423ms/step - accuracy: 0.7049 - loss: 0.8173 - val_accuracy: 0.7302 - val_loss: 0.7824\n",
      "Epoch 81/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7053 - loss: 0.8038\n",
      "Epoch 81: accuracy did not improve from 0.72571\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 415ms/step - accuracy: 0.7056 - loss: 0.8031 - val_accuracy: 0.7421 - val_loss: 0.7621\n",
      "Epoch 82/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.7047 - loss: 0.8094\n",
      "Epoch 82: accuracy improved from 0.72571 to 0.72615, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 416ms/step - accuracy: 0.7053 - loss: 0.8085 - val_accuracy: 0.7103 - val_loss: 0.7287\n",
      "Epoch 83/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.7119 - loss: 0.7588\n",
      "Epoch 83: accuracy did not improve from 0.72615\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 426ms/step - accuracy: 0.7121 - loss: 0.7591 - val_accuracy: 0.7143 - val_loss: 0.7410\n",
      "Epoch 84/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.6926 - loss: 0.8094\n",
      "Epoch 84: accuracy did not improve from 0.72615\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 454ms/step - accuracy: 0.6933 - loss: 0.8084 - val_accuracy: 0.7421 - val_loss: 0.6855\n",
      "Epoch 85/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.7314 - loss: 0.7563\n",
      "Epoch 85: accuracy improved from 0.72615 to 0.73670, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 421ms/step - accuracy: 0.7316 - loss: 0.7559 - val_accuracy: 0.7540 - val_loss: 0.7047\n",
      "Epoch 86/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.7285 - loss: 0.7535\n",
      "Epoch 86: accuracy did not improve from 0.73670\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 443ms/step - accuracy: 0.7286 - loss: 0.7530 - val_accuracy: 0.7381 - val_loss: 0.7314\n",
      "Epoch 87/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.6758 - loss: 0.8719\n",
      "Epoch 87: accuracy did not improve from 0.73670\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 416ms/step - accuracy: 0.6769 - loss: 0.8697 - val_accuracy: 0.7579 - val_loss: 0.6573\n",
      "Epoch 88/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7375 - loss: 0.7334\n",
      "Epoch 88: accuracy improved from 0.73670 to 0.74549, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 409ms/step - accuracy: 0.7377 - loss: 0.7332 - val_accuracy: 0.7381 - val_loss: 0.7272\n",
      "Epoch 89/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.6767 - loss: 0.8703\n",
      "Epoch 89: accuracy did not improve from 0.74549\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 403ms/step - accuracy: 0.6773 - loss: 0.8686 - val_accuracy: 0.7619 - val_loss: 0.7607\n",
      "Epoch 90/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.7210 - loss: 0.7760\n",
      "Epoch 90: accuracy did not improve from 0.74549\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 441ms/step - accuracy: 0.7212 - loss: 0.7758 - val_accuracy: 0.7540 - val_loss: 0.6869\n",
      "Epoch 91/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7225 - loss: 0.7712\n",
      "Epoch 91: accuracy did not improve from 0.74549\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 412ms/step - accuracy: 0.7231 - loss: 0.7699 - val_accuracy: 0.7381 - val_loss: 0.7862\n",
      "Epoch 92/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.7120 - loss: 0.7863\n",
      "Epoch 92: accuracy did not improve from 0.74549\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 411ms/step - accuracy: 0.7126 - loss: 0.7850 - val_accuracy: 0.7579 - val_loss: 0.6914\n",
      "Epoch 93/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.7218 - loss: 0.7513\n",
      "Epoch 93: accuracy did not improve from 0.74549\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 407ms/step - accuracy: 0.7224 - loss: 0.7503 - val_accuracy: 0.7619 - val_loss: 0.6697\n",
      "Epoch 94/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.7314 - loss: 0.7470\n",
      "Epoch 94: accuracy improved from 0.74549 to 0.75429, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 411ms/step - accuracy: 0.7320 - loss: 0.7457 - val_accuracy: 0.7341 - val_loss: 0.6872\n",
      "Epoch 95/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6848 - loss: 0.8993\n",
      "Epoch 95: accuracy did not improve from 0.75429\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 413ms/step - accuracy: 0.6859 - loss: 0.8958 - val_accuracy: 0.7579 - val_loss: 0.6673\n",
      "Epoch 96/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7265 - loss: 0.7238\n",
      "Epoch 96: accuracy did not improve from 0.75429\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 418ms/step - accuracy: 0.7272 - loss: 0.7231 - val_accuracy: 0.7381 - val_loss: 0.7007\n",
      "Epoch 97/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.7417 - loss: 0.7275\n",
      "Epoch 97: accuracy improved from 0.75429 to 0.76440, saving model to ckpt/cnn_v2.weights.h5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 426ms/step - accuracy: 0.7424 - loss: 0.7259 - val_accuracy: 0.7302 - val_loss: 0.7053\n",
      "Epoch 98/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7288 - loss: 0.7659\n",
      "Epoch 98: accuracy did not improve from 0.76440\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.7290 - loss: 0.7651 - val_accuracy: 0.7619 - val_loss: 0.6648\n",
      "Epoch 99/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.7465 - loss: 0.7210\n",
      "Epoch 99: accuracy did not improve from 0.76440\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 419ms/step - accuracy: 0.7463 - loss: 0.7212 - val_accuracy: 0.7421 - val_loss: 0.6752\n",
      "Epoch 100/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.7298 - loss: 0.7353\n",
      "Epoch 100: accuracy did not improve from 0.76440\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 431ms/step - accuracy: 0.7299 - loss: 0.7348 - val_accuracy: 0.7778 - val_loss: 0.6423\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks_list,\n",
    "    steps_per_epoch=len(train_ds),\n",
    "    validation_steps=len(val_ds),\n",
    "    # class_weight=class_weights, #include the class weight\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▂▂▄▄▄▅▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██▇▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▄▄▅▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇███████▇█</td></tr><tr><td>epoch/val_loss</td><td>▆█▄▄▄▄▃▃▃▃▃▂▂▂▄▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.74066</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.69952</td></tr><tr><td>epoch/val_accuracy</td><td>0.77778</td></tr><tr><td>epoch/val_loss</td><td>0.64227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-spaceship-12</strong> at: <a href='https://wandb.ai/agungadipurwa_/trashnet-classification/runs/mmu9pem7' target=\"_blank\">https://wandb.ai/agungadipurwa_/trashnet-classification/runs/mmu9pem7</a><br> View project at: <a href='https://wandb.ai/agungadipurwa_/trashnet-classification' target=\"_blank\">https://wandb.ai/agungadipurwa_/trashnet-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 84 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241222_213430-mmu9pem7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Saving model\n",
    "path = \"./ckpt/cnn_v2.weights.h5\" #save modle on local\n",
    "registered_model_name = \"cnn_trashnet_v2\" #push model for tacking versioning or experiment to Wandb\n",
    "\n",
    "run.link_model(path=path, registered_model_name=registered_model_name)\n",
    "run.finish() #close the running session of Wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
